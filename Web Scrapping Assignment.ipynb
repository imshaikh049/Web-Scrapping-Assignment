{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae07ce71-2a16-4dc7-8442-f9fbbc7de70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "Web Scraping is a technique used to extract data from websites by accessing the HTML of web pages and parsing it to retrieve relevant information.\n",
    "Why it is used: It is used to collect large amounts of data automatically from the web for various purposes such as analysis, research, and automation.\n",
    "Areas where Web Scraping is used:\n",
    "E-commerce: To gather price data, reviews, or product information.\n",
    "Real Estate: To extract property listings and market trends.\n",
    "Social Media: To collect public opinions, trends, or user behaviors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eb4cc3-4c9e-4ef7-b30c-5fe0e300c1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What are the different methods used for Web Scraping?\n",
    "Methods used for Web Scraping:\n",
    "Manual Copy-Pasting: Manually extracting data by copying it.\n",
    "HTTP Libraries: Using libraries like requests to send HTTP requests and retrieve page content.\n",
    "HTML Parsing: Parsing the HTML content using libraries like Beautiful Soup or lxml.\n",
    "Browser Automation: Using tools like Selenium to interact with JavaScript-heavy websites.\n",
    "APIs: Accessing public or private APIs to retrieve data directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdd6bf6-b79f-496a-af69-a61e62e450d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?\n",
    "Beautiful Soup is a Python library used for parsing HTML and XML documents. It creates a parse tree for parsed pages and helps to extract the required data easily.\n",
    "Why it is used: It simplifies the process of navigating, searching, and modifying the parsed HTML or XML, making it useful for web scraping projects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2a4a47-59ee-4126-93b6-7c1db9b73dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Why is Flask used in this Web Scraping project?\n",
    "Flask is used in the web scraping project to create a web interface where users can interact with the scraper, initiate scraping tasks, and display the scraped data. It serves as the backend for the web application.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed5c7e7-f6c4-4b30-b809-4ea3084da5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "AWS Services used in the project might include:\n",
    "Amazon EC2 (Elastic Compute Cloud): Used to host the web scraper or deploy the web application.\n",
    "Amazon S3 (Simple Storage Service): Used to store large volumes of scraped data securely.\n",
    "AWS Lambda: Used for executing scraping tasks in a serverless environment, triggered by events like data updates or time schedules.\n",
    "Amazon RDS (Relational Database Service): Used to store the scraped data in a relational database like MySQL or PostgreSQL.\n",
    "Amazon CloudWatch: Used to monitor and log web scraping activities, ensuring optimal performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
